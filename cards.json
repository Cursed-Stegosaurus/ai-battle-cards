[
  {
    "id": "Artificer",
    "title": "Artificer\u2002-\u2002ChatGPT-o3",
    "front": "Cards/Artificer.jpg",
    "what": "What it is.\u00a0OpenAI\u2019s \u201co3\u201d is the most reasoning-dense model available to the public. Think of it as a CNC mill for ideas: feed it a fuzzy problem, and it iteratively carves out logic, equations, or code until the edges are sharp."
  },
  {
    "id": "Why it made the deck.\u00a0You rely on it as a\u00a0daily driver for hard things",
    "title": "Why it made the deck.\u00a0You rely on it as a\u00a0daily driver for hard things-actuarial tables, SQL migrations, multi-stage prompt chains. Nothing else packs this much reliability into a single call.",
    "front": "Cards/Why it made the deck.\u00a0You rely on it as a\u00a0daily driver for hard things.jpg",
    "why": "When to play it.\u00a0\u2022 Designing data schemas\u2002\u2022 Debugging opaque stack traces\u2002\u2022 Writing memos where wrong math is reputationally fatal.",
    "when": [
      "Designing data schemas\u2002",
      "Debugging opaque stack traces\u2002",
      "Writing memos where wrong math is reputationally fatal"
    ],
    "watch": "Watch-outs.\u00a0Slower and pricier than mid-range models; best used when the extra IQ will be\u00a0noticed."
  },
  {
    "id": "Companion",
    "title": "Companion\u2002-\u2002ChatGPT-4o",
    "front": "Cards/Companion.jpg",
    "what": "What it is.\u00a0The \u201co\u201d stands for omni: text, voice, and vision in one lightweight wrapper. It trades raw depth for latency and warmth."
  },
  {
    "id": "Why included.\u00a0It\u2019s the friend who answers on the first ring",
    "title": "Why included.\u00a0It\u2019s the friend who answers on the first ring-perfect for rapid notes, screen-share brainstorming, or photo-based quick fixes.",
    "front": "Cards/Why included.\u00a0It\u2019s the friend who answers on the first ring.jpg",
    "why": "Sweet spots.\u00a0\u2022 Annotating screenshots\u2002\u2022 Explaining a diagram by voice\u2002\u2022 Tossing together a polite reply before you board a plane.",
    "when": [
      "Annotating screenshots\u2002",
      "Explaining a diagram by voice\u2002",
      "Tossing together a polite reply before you board a plane"
    ],
    "watch": "Limitations.\u00a0Doesn\u2019t sweat edge cases; for rigorous analysis hand the baton back to Artificer or Strategist."
  },
  {
    "id": "Strategist",
    "title": "Strategist\u2002-\u2002GPT-4.1",
    "front": "Cards/Strategist.jpg",
    "what": "What it is.\u00a0The flagship successor to GPT-4 Turbo. Same calm prose, sharper long-range sense-making."
  },
  {
    "id": "Why included.\u00a0You keep reaching for it when the\u00a0shape\u00a0of a solution matters more than the pixels",
    "title": "Why included.\u00a0You keep reaching for it when the\u00a0shape\u00a0of a solution matters more than the pixels-product road-maps, proposal trade-offs, scenario planning.",
    "front": "Cards/Why included.\u00a0You keep reaching for it when the\u00a0shape\u00a0of a solution matters more than the pixels.jpg",
    "why": "Plays well with.\u00a0\u2022 Causal diagrams\u2002\u2022 OKR roll-downs\u2002\u2022 Competitive-landscape memos.",
    "when": [
      "Causal diagrams\u2002",
      "OKR roll-downs\u2002",
      "Competitive-landscape memos"
    ],
    "watch": "Caveats.\u00a0Costlier tokens than 4o; context still capped at 256 k, so ultra-long docs belong to Oracle."
  },
  {
    "id": "Prodigy",
    "title": "Prodigy\u2002-\u2002GPT-4.5 preview",
    "front": "Cards/Prodigy.jpg"
  },
  {
    "id": "What it is.\u00a0An early peek at OpenAI\u2019s 4.5",
    "title": "What it is.\u00a0An early peek at OpenAI\u2019s 4.5-smart, capable, expensive and getting retired soon! Not for long though-expect this to be the backbone of the rumored GPT-5.",
    "front": "Cards/What it is.\u00a0An early peek at OpenAI\u2019s 4.5.jpg",
    "why": "Use cases.\u00a0\u2022 Creative writing\u2002\u2022 EQ conversations\u2002\u2022 Writing critique.",
    "when": [
      "Creative writing\u2002",
      "EQ conversations\u2002",
      "Writing critique"
    ],
    "watch": "Gotchas.\u00a0Preview means it won\u2019t always be here, so enjoy it while it lasts."
  },
  {
    "id": "Polymath",
    "title": "Polymath\u2002-\u2002Claude-4 Opus",
    "front": "Cards/Polymath.jpg",
    "what": "What it is.\u00a0Anthropic\u2019s largest model, famous for graceful prose and strong coding ability, especially complex coding problem-solving."
  },
  {
    "id": "Why included.\u00a0It threads the needle between technical rigor and executive polish",
    "title": "Why included.\u00a0It threads the needle between technical rigor and executive polish-and plugs straight into Gmail/Calendar in the Claude app.",
    "front": "Cards/Why included.\u00a0It threads the needle between technical rigor and executive polish.jpg",
    "why": "Shines at.\u00a0\u2022 Complex refactors written like a consultant\u2019s playbook\u2002\u2022 Policy drafts that actually\u00a0sound human.",
    "when": [
      "Complex refactors written like a consultant\u2019s playbook\u2002",
      "Policy drafts that actually\u00a0sound human"
    ],
    "watch": "Limits.\u00a0Slightly narrower tool-calling APIs than OpenAI; can stall in long chats."
  },
  {
    "id": "Composer",
    "title": "Composer\u2002-\u2002Claude 3.5 Sonnet",
    "front": "Cards/Composer.jpg",
    "what": "What it is.\u00a0Anthropic\u2019s \u201cmiddle-weight\u201d model: smaller than Opus, faster than anything its size, and trained to keep a lyrical, on-brand voice. Brilliant at composing code."
  },
  {
    "id": "Why included.\u00a0It\u2019s the go-to when you need\u00a0speed plus style",
    "title": "Why included.\u00a0It\u2019s the go-to when you need\u00a0speed plus style-edit copy live on a call, polish slides minutes before the meeting, or refactor 200 lines of code while stakeholders watch.",
    "front": "Cards/Why included.\u00a0It\u2019s the go-to when you need\u00a0speed plus style.jpg",
    "why": "Sweet spots.\u00a0\u2022 Real-time writing coach\u2003\u2022 Tone-matching executive summaries\u2003\u2022 Rapid code patches with clean explanations.",
    "when": [
      "Real-time writing coach\u2003",
      "Tone-matching executive summaries\u2003",
      "Rapid code patches with clean explanations"
    ],
    "watch": "Watch-outs.\u00a0Hard problems still belong to Opus or Artificer; token context tops out sooner than you want."
  },
  {
    "id": "Oracle",
    "title": "Oracle\u2002-\u2002Gemini 2.5 Pro / Ultra",
    "front": "Cards/Oracle.jpg",
    "what": "What it is.\u00a0Google\u2019s flagship with million-token context and a strong fact-checking layer.",
    "why": "Shines at.\u00a0\u2022 Cross-checking stats\u2003\u2022 Summarising litigation troves\u2003\u2022 Ingesting entire wikis for \u201cone-pager\u201d outputs.",
    "when": [
      "Cross-checking stats\u2003",
      "Summarising litigation troves\u2003",
      "Ingesting entire wikis for \u201cone-pager\u201d outputs"
    ]
  },
  {
    "id": "Limits.\u00a0Thinks more than 4o, occasionally overly cautious, has a little bit of fuzziness following some instructions",
    "title": "Limits.\u00a0Thinks more than 4o, occasionally overly cautious, has a little bit of fuzziness following some instructions-have Strategist tighten conclusions.",
    "front": "Cards/Limits.\u00a0Thinks more than 4o, occasionally overly cautious, has a little bit of fuzziness following some instructions.jpg"
  },
  {
    "id": "Scholar",
    "title": "Scholar\u2002-\u2002ChatGPT Deep Research",
    "front": "Cards/Scholar.jpg",
    "what": "What it is.\u00a0A special OpenAI variant tuned for long, self-directed research runs (10\u201320 minutes).",
    "why": "Sweet spots.\u00a0\u2022 Competitive landscapes\u2003\u2022 Historical chronologies\u2003\u2022 \u201cExplain this like I\u2019m new, with sources.\u201d",
    "when": [
      "Competitive landscapes\u2003",
      "Historical chronologies\u2003",
      "\u201cExplain this like I\u2019m new, with sources.\u201d"
    ]
  },
  {
    "id": "Watch-outs.\u00a0Not interactive in real time",
    "title": "Watch-outs.\u00a0Not interactive in real time-hand the baton back to Companion for quick Q&A.",
    "front": "Cards/Watch-outs.\u00a0Not interactive in real time.jpg"
  },
  {
    "id": "Prospector",
    "title": "Prospector\u2002-\u2002DeepSeek R1",
    "front": "Cards/Prospector.jpg"
  },
  {
    "id": "What it is.\u00a0A Chinese-led open model that just cracked the top-10 in code benchmarks",
    "title": "What it is.\u00a0A Chinese-led open model that just cracked the top-10 in code benchmarks-at a fraction of Big-Tech inference cost.",
    "front": "Cards/What it is.\u00a0A Chinese-led open model that just cracked the top-10 in code benchmarks.jpg",
    "why": "Use cases.\u00a0\u2022 Bulk code stubs\u2003\u2022 STEM problem sets\u2003\u2022 Bilingual chatbot demos.",
    "when": [
      "Bulk code stubs\u2003",
      "STEM problem sets\u2003",
      "Bilingual chatbot demos"
    ],
    "watch": "Caveats.\u00a0Slightly lower on scores than o3. More importantly, the Terms of Service aren\u2019t friendly to most US or EU business use-cases."
  },
  {
    "id": "Collective",
    "title": "Collective\u2002-\u2002Mixtral 8 \u00d7 22B",
    "front": "Cards/Collective.jpg",
    "what": "What it is.\u00a0An open Mixture-of-Experts (MoE): eight specialist subnetworks \u201cvote\u201d on every token."
  },
  {
    "id": "Why included.\u00a0It delivers near-Claude quality while staying fully open-weight",
    "title": "Why included.\u00a0It delivers near-Claude quality while staying fully open-weight-ideal for privacy-sensitive or air-gapped deployments.",
    "front": "Cards/Why included.\u00a0It delivers near-Claude quality while staying fully open-weight.jpg",
    "why": "Shines at.\u00a0\u2022 Self-hosted knowledge bots\u2003\u2022 On-prem RAG stacks\u2003\u2022 Fast fine-tunes with low GPU budgets.",
    "when": [
      "Self-hosted knowledge bots\u2003",
      "On-prem RAG stacks\u2003",
      "Fast fine-tunes with low GPU budgets"
    ],
    "watch": "Limits.\u00a0MoE routing sometimes misfires on niche queries; heavier model-loading logistics than plain Llama."
  },
  {
    "id": "Voyager",
    "title": "Voyager\u2002-\u2002Yi-1.5 200B",
    "front": "Cards/Voyager.jpg",
    "what": "What it is.\u00a001.AI\u2019s large bilingual model, fluent in English and Chinese and permissively licensed.",
    "why": "Sweet spots.\u00a0\u2022 Cross-border product copy\u2003\u2022 Dual-language knowledge bases\u2003\u2022 Fine-tunes for APAC markets.",
    "when": [
      "Cross-border product copy\u2003",
      "Dual-language knowledge bases\u2003",
      "Fine-tunes for APAC markets"
    ]
  },
  {
    "id": "Watch-outs.\u00a0High GPU memory footprint; English style slightly stiffer than Opus",
    "title": "Watch-outs.\u00a0High GPU memory footprint; English style slightly stiffer than Opus-polish with Composer if tone matters.",
    "front": "Cards/Watch-outs.\u00a0High GPU memory footprint; English style slightly stiffer than Opus.jpg"
  },
  {
    "id": "Diplomat",
    "title": "Diplomat\u2002-\u2002Cohere Command R+",
    "front": "Cards/Diplomat.jpg",
    "what": "What it is.\u00a0Cohere\u2019s enterprise-tuned model, optimised for Retrieval-Augmented Generation (RAG) and multi-step tool use.",
    "why": "Plays well with.\u00a0\u2022 Internal knowledge bots\u2003\u2022 Compliance summaries\u2003\u2022 Multi-step workflows.",
    "when": [
      "Internal knowledge bots\u2003",
      "Compliance summaries\u2003",
      "Multi-step workflows"
    ],
    "watch": "Limits.\u00a0Designed for workflows more than writing; for marketing copy pair with Companion or Composer."
  },
  {
    "id": "Commons",
    "title": "Commons\u2002-\u2002Llama 3 405B",
    "front": "Cards/Commons.jpg"
  },
  {
    "id": "What it is.\u00a0Meta\u2019s largest open model",
    "title": "What it is.\u00a0Meta\u2019s largest open model-basically \u201cChatGPT-3.5 quality, but yours to tinker with.\u201d",
    "front": "Cards/What it is.\u00a0Meta\u2019s largest open model.jpg",
    "why": "Use cases.\u00a0\u2022 Private-cloud assistants\u2003\u2022 Domain-specific fine-tunes\u2003\u2022 Academic experiments.",
    "when": [
      "Private-cloud assistants\u2003",
      "Domain-specific fine-tunes\u2003",
      "Academic experiments"
    ],
    "watch": "Caveats.\u00a0No built-in tools API; connect external RAG or function-calling layers yourself."
  },
  {
    "id": "Navigator",
    "title": "Navigator\u2002-\u2002Mistral Large",
    "front": "Cards/Navigator.jpg",
    "what": "What it is.\u00a0A large model cousin to Mixtral; designed for intelligence inference and coding abilities.",
    "why": "Shines at.\u00a0Instruction following abilities, strong at coding and inference.",
    "when": [],
    "watch": "Limits.\u00a0Not a true top 3 model; for heavy analysis use Artificer or Strategist."
  },
  {
    "id": "Maverick",
    "title": "Maverick\u2002-\u2002Grok-2",
    "front": "Cards/Maverick.jpg",
    "what": "What it is.\u00a0xAI\u2019s second generation, personality-forward model with a cheeky tone and access to real-time information.",
    "why": "Sweet spots.\u00a0\u2022 Brainstorm sessions\u2003\u2022 Solid coding abilities \u2022 Good creative problem-solving sense",
    "when": [
      "Brainstorm sessions\u2003",
      "Solid coding abilities",
      "Good creative problem-solving sense"
    ],
    "watch": "Watch-outs.\u00a0Can veer informal; run final drafts through Composer for polish. No published model card and a number of prominent model alignment issues."
  },
  {
    "id": "Scout",
    "title": "Scout\u2002-\u2002Perplexity Sonar",
    "front": "Cards/Scout.jpg"
  },
  {
    "id": "What it is.\u00a0A retrieval-native model that always cites sources",
    "title": "What it is.\u00a0A retrieval-native model that always cites sources-think \u201cAI search-engine in a box.\u201d",
    "front": "Cards/What it is.\u00a0A retrieval-native model that always cites sources.jpg",
    "why": "Use cases.\u00a0\u2022 Quick news briefs\u2003\u2022 \u201cShow me five recent papers on\u2026\u201d\u2003\u2022 Pre-meeting fact scouting.",
    "when": [
      "Quick news briefs\u2003",
      "\u201cShow me five recent papers on\u2026\u201d\u2003",
      "Pre-meeting fact scouting"
    ],
    "watch": "Caveats.\u00a0Depends on live web access, purpose-built for search."
  }
]